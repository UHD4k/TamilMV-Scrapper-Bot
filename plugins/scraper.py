from cloudscraper import create_scraper
from re import sub
from bs4 import BeautifulSoup

async def tamilmv(url):
    cget = create_scraper().request
    resp = cget("GET", url)
    soup = BeautifulSoup(resp.text, "html.parser")
    mag = soup.select('a[href^="magnet:?xt=urn:btih:"]')
    tor = soup.select('a[data-fileext="torrent"]')
    parse_data = f"<b><u>{soup.title.string}</u></b>"
    for no, (t, m) in enumerate(zip(tor, mag), start=1):
        filename = sub(r"www\S+|\- |\.torrent", "", t.string)
        parse_data += f"""
        
{no}. <code>{filename}</code>
â”– <b>Links :</b> <a href="https://t.me/share/url?url={m['href'].split('&')[0]}"><b>Magnet </b>ğŸ§²</a>  | <a href="{t['href']}"><b>Torrent ğŸŒ</b></a>"""
    return parse_data

async def tamilmv1(url):
    cget = create_scraper().request
    resp = cget("GET", url)
    soup = BeautifulSoup(resp.text, "html.parser")
    tor = soup.select('a[data-fileext="torrent"]')

    torrent_links = []  # List to store torrent links only
    formatted_links = []  # List to store the formatted text output
    
    for t in tor:
        torrent_link = t['href']
        torrent_links.append(torrent_link)
        formatted_links.append(f"/qbleech {torrent_link}")
    
    # Return the formatted links as a string and the raw torrent links as a list
    return "\n".join(formatted_links), torrent_links
